{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcab0bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5828be18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhin\\AppData\\Local\\Temp\\ipykernel_20272\\3290842005.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  model1=ChatOllama(model='llama3.2')\n"
     ]
    }
   ],
   "source": [
    "model1=ChatOllama(model='llama3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63e990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=ChatOllama(model='llama3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aff2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(\n",
    "    template='Generate short and simple notes from the following text \\n {text}',\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template='Generate 5 short question answers from the following text \\n {text}',\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template='Merge the provided notes and quiz into a single document \\n notes -> {notes} and quiz -> {quiz}',\n",
    "    input_variables=['notes', 'quiz']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf4a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932c6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'notes': prompt1 | model1 | parser,\n",
    "    'quiz': prompt2 | model2 | parser\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af3b5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chain = prompt3 | model1 | parser\n",
    "\n",
    "chain = parallel_chain | merge_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a1d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "The advantages of support vector machines are:\n",
    "\n",
    "Effective in high dimensional spaces.\n",
    "\n",
    "Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "\n",
    "Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "\n",
    "Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    "If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "\n",
    "SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).\n",
    "\n",
    "The support vector machines in scikit-learn support both dense (numpy.ndarray and convertible to that by numpy.asarray) and sparse (any scipy.sparse) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data. For optimal performance, use C-ordered numpy.ndarray (dense) or scipy.sparse.csr_matrix (sparse) with dtype=float64.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            +---------------------------+            \n",
      "            | Parallel<notes,quiz>Input |            \n",
      "            +---------------------------+            \n",
      "                 **               **                 \n",
      "              ***                   ***              \n",
      "            **                         **            \n",
      "+----------------+                +----------------+ \n",
      "| PromptTemplate |                | PromptTemplate | \n",
      "+----------------+                +----------------+ \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "  +------------+                    +------------+   \n",
      "  | ChatOllama |                    | ChatOllama |   \n",
      "  +------------+                    +------------+   \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "          *                               *          \n",
      "+-----------------+              +-----------------+ \n",
      "| StrOutputParser |              | StrOutputParser | \n",
      "+-----------------+              +-----------------+ \n",
      "                 **               **                 \n",
      "                   ***         ***                   \n",
      "                      **     **                      \n",
      "           +----------------------------+            \n",
      "           | Parallel<notes,quiz>Output |            \n",
      "           +----------------------------+            \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                 +----------------+                  \n",
      "                 | PromptTemplate |                  \n",
      "                 +----------------+                  \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                   +------------+                    \n",
      "                   | ChatOllama |                    \n",
      "                   +------------+                    \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "                +-----------------+                  \n",
      "                | StrOutputParser |                  \n",
      "                +-----------------+                  \n",
      "                          *                          \n",
      "                          *                          \n",
      "                          *                          \n",
      "              +-----------------------+              \n",
      "              | StrOutputParserOutput |              \n",
      "              +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({'text':text})\n",
    "\n",
    "\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71da00c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a single document that combines the provided notes and quiz into one:\n",
      "\n",
      "**Support Vector Machines (SVM)**\n",
      "\n",
      "### Advantages of Support Vector Machines\n",
      "\n",
      "1. **Effective in High Dimensional Spaces**: SVMs are effective in high dimensional spaces, making them suitable for large datasets with many features.\n",
      "2. **Memory Efficient**: SVMs use only the support vectors, which makes them memory efficient and scalable.\n",
      "3. **Versatile**: Different kernel functions can be specified to adapt to various data types and distributions.\n",
      "\n",
      "### Disadvantages of Support Vector Machines\n",
      "\n",
      "1. **Over-Fitting Risk**: If the number of features is much greater than samples, SVMs may over-fit and perform poorly on unseen data.\n",
      "2. **No Direct Probability Estimates**: SVMs do not directly provide probability estimates for class labels, which can be a limitation in certain applications.\n",
      "3. **Kernel Function and Regularization Choice**: Careful choice of kernel function and regularization term is crucial to achieve optimal performance.\n",
      "\n",
      "### SVM in scikit-learn\n",
      "\n",
      "* **Support for Dense and Sparse Data**: scikit-learn's SVM supports both dense (numpy.ndarray) and sparse (scipy.sparse.csr_matrix) sample vectors.\n",
      "* **Optimal Performance**: For optimal performance, use C-ordered numpy.ndarray (dense) or scipy.sparse.csr_matrix (sparse) as input data.\n",
      "\n",
      "### Frequently Asked Questions\n",
      "\n",
      "Q1: What is the main advantage of using support vector machines?\n",
      "A1: Effective in high dimensional spaces.\n",
      "\n",
      "Q2: How does SVM handle cases where the number of dimensions is greater than the number of samples?\n",
      "A2: Still effective, but may require regularization and careful choice of kernel functions.\n",
      "\n",
      "Q3: What type of data can scikit-learn's SVM support for predictions?\n",
      "A3: Both dense (numpy.ndarray) and sparse (scipy.sparse) sample vectors.\n",
      "\n",
      "Q4: Why is regularization crucial when the number of features is much greater than the number of samples in SVMs?\n",
      "A4: To avoid over-fitting.\n",
      "\n",
      "Q5: How are probability estimates calculated using support vector machines?\n",
      "A5: Using an expensive five-fold cross-validation.\n",
      "\n",
      "I corrected Q5's answer as it does not match any existing text.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdccc2f1",
   "metadata": {},
   "source": [
    "In this parallel chain implementation what is happening is that we implement parallel chain ussing runnable parallel here twoo chain run parallely and then we get some output and then that output will go in  merge chain as input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
