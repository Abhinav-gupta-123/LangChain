{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b09275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a tool for large language models (LLMs) that helps simplify the process of integrating them with other applications and services.\n",
      "\n",
      "Think of a large language model like a super-smart librarian who can answer any question you ask it, based on the vast amount of text data it was trained on. However, this librarian might not have access to all the information you need, or might not know how to retrieve it from your application.\n",
      "\n",
      "LangChain is like an intermediary that helps connect the language model to other services and applications. It acts as a \"middleware\" layer, allowing developers to:\n",
      "\n",
      "1. Integrate LLMs with their existing applications\n",
      "2. Use the LLM's capabilities in a more seamless way\n",
      "3. Handle tasks such as data retrieval, storage, and processing\n",
      "\n",
      "In simple terms, LangChain is like a bridge that helps large language models talk to other systems and services, making it easier for developers to build powerful AI-powered applications.\n",
      "\n",
      "To illustrate this, imagine you're building an e-commerce platform that uses a LLM to suggest product recommendations. With LangChain, the LLM can seamlessly interact with your platform's database, retrieve product information, and provide personalized suggestions â€“ all without requiring significant custom development.\n",
      "\n",
      "Overall, LangChain simplifies the process of working with large language models by providing a standardized interface for integration and interaction.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Load the model (it will connect\" to the local Ollama server running llama3.2)\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "# Ask a question\n",
    "response = llm.invoke([\n",
    "    HumanMessage(content=\"Explain LangChain in terms of large language models in simple terms.\")\n",
    "])\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5dbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
