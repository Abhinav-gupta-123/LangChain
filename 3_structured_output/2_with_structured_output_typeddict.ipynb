{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0fefe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhin\\AppData\\Local\\Temp\\ipykernel_21724\\4144517650.py:7: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  model = ChatOllama(model=\"llama3.2\")\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m     cons: Annotated[Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite down all the cons inside a list\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     18\u001b[0m     name: Annotated[Optional[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite the name of the reviewer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 21\u001b[0m structured_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mReview\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m result \u001b[38;5;241m=\u001b[39m structured_model\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mI recently upgraded to the Samsung Galaxy S24 Ultra, and I must say, it’s an absolute powerhouse! The Snapdragon 8 Gen 3 processor makes everything lightning fast—whether I’m gaming, multitasking, or editing photos. The 5000mAh battery easily lasts a full day even with heavy use, and the 45W fast charging is a lifesaver.\u001b[39m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124mThe S-Pen integration is a great touch for note-taking and quick sketches, though I don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it often. What really blew me away is the 200MP camera—the night mode is stunning, capturing crisp, vibrant images even in low light. Zooming up to 100x actually works well for distant objects, but anything beyond 30x loses quality.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124mReview by Nitish Singh\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\abhin\\Desktop\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1441\u001b[0m, in \u001b[0;36mBaseChatModel.with_structured_output\u001b[1;34m(self, schema, include_raw, **kwargs)\u001b[0m\n\u001b[0;32m   1438\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_structured_output is not implemented for this model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[1;32m-> 1441\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_tools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43many\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mls_structured_output_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1445\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_calling\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mschema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_basemodel_subclass(schema):\n\u001b[0;32m   1450\u001b[0m     output_parser: OutputParserLike \u001b[38;5;241m=\u001b[39m PydanticToolsParser(\n\u001b[0;32m   1451\u001b[0m         tools\u001b[38;5;241m=\u001b[39m[cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypeBaseModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, schema)], first_tool_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1452\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\abhin\\Desktop\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1315\u001b[0m, in \u001b[0;36mBaseChatModel.bind_tools\u001b[1;34m(self, tools, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind_tools\u001b[39m(\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1299\u001b[0m     tools: Sequence[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1305\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Runnable[LanguageModelInput, BaseMessage]:\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Bind tools to the model.\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m        A Runnable that returns a message.\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, Optional, Literal\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Load the model (it will connect\" to the local Ollama server running llama3.2)\n",
    "model = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "\n",
    "# schema\n",
    "class Review(TypedDict):\n",
    "\n",
    "    key_themes: Annotated[list[str], \"Write down all the key themes discussed in the review in a list\"]\n",
    "    summary: Annotated[str, \"A brief summary of the review\"]\n",
    "    sentiment: Annotated[Literal[\"pos\", \"neg\"], \"Return sentiment of the review either negative, positive or neutral\"]\n",
    "    pros: Annotated[Optional[list[str]], \"Write down all the pros inside a list\"]\n",
    "    cons: Annotated[Optional[list[str]], \"Write down all the cons inside a list\"]\n",
    "    name: Annotated[Optional[str], \"Write the name of the reviewer\"]\n",
    "    \n",
    "\n",
    "structured_model = model.with_structured_output(Review)\n",
    "\n",
    "result = structured_model.invoke(\"\"\"I recently upgraded to the Samsung Galaxy S24 Ultra, and I must say, it’s an absolute powerhouse! The Snapdragon 8 Gen 3 processor makes everything lightning fast—whether I’m gaming, multitasking, or editing photos. The 5000mAh battery easily lasts a full day even with heavy use, and the 45W fast charging is a lifesaver.\n",
    "\n",
    "The S-Pen integration is a great touch for note-taking and quick sketches, though I don't use it often. What really blew me away is the 200MP camera—the night mode is stunning, capturing crisp, vibrant images even in low light. Zooming up to 100x actually works well for distant objects, but anything beyond 30x loses quality.\n",
    "\n",
    "However, the weight and size make it a bit uncomfortable for one-handed use. Also, Samsung’s One UI still comes with bloatware—why do I need five different Samsung apps for things Google already provides? The $1,300 price tag is also a hard pill to swallow.\n",
    "\n",
    "Pros:\n",
    "Insanely powerful processor (great for gaming and productivity)\n",
    "Stunning 200MP camera with incredible zoom capabilities\n",
    "Long battery life with fast charging\n",
    "S-Pen support is unique and useful\n",
    "                                 \n",
    "Review by Abhinav gupta\n",
    "\"\"\")\n",
    "print(result['name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f550db",
   "metadata": {},
   "source": [
    "So,the error we are getting is because currently langchain does not support the  \n",
    "with_structured_output() method for ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193390fb",
   "metadata": {},
   "source": [
    "If you have open api key ,thes use them it support the structured output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea7be4a",
   "metadata": {},
   "source": [
    "# There is one problem with typeddict is as we applied the data type in annotation but there is no guarantee that llm will return the string if we use str it may can mistake so there is no guarantee for data validation ,for data validation we have pydantic lets see about pydantic,how it help or ensure the data valdaiton in next file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e8814",
   "metadata": {},
   "source": [
    "Ex for clerification\n",
    "\n",
    "Annotated[list[str], \"Write down all the key themes discussed in the review in a list\"\n",
    "\n",
    "it is not guaranted that it will generate only string formate "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
